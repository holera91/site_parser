import gspread
from google.oauth2.service_account import Credentials
import requests
from bs4 import BeautifulSoup
import logging
from urllib.parse import urljoin
from langdetect import detect
from deep_translator import GoogleTranslator
from concurrent.futures import ThreadPoolExecutor
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Google Sheets
_client = None

def authenticate_google_sheets():
    global _client
    if _client is not None:
        return _client

    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    try:
        creds = Credentials.from_service_account_file("credentials.json", scopes=scope)
        _client = gspread.authorize(creds)
        logging.info("‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ Google Sheets.")
        return _client
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        raise

def get_business_websites(sheet_name):
    try:
        client = authenticate_google_sheets()
        sheet = client.open(sheet_name).sheet1
        websites = sheet.col_values(1)
        num_sites = len(websites) - 1
        logging.info(f"üìå –ü–æ–ª—É—á–µ–Ω–æ {num_sites} —Å–∞–π—Ç–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã.")
        return websites[1:]  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã: {e}")
        return []

def detect_page_language(html):
    try:
        soup = BeautifulSoup(html, "html.parser")
        lang_tag = soup.find("html").get("lang")
        if lang_tag:
            return lang_tag.split("-")[0]
        return detect(html)
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —è–∑—ã–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
        return "en"

def translate_keywords(keywords, target_lang):
    try:
        translated_keywords = [GoogleTranslator(source="en", target=target_lang).translate(word) for word in keywords]
        logging.info(f"üåç –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã –Ω–∞ {target_lang}: {translated_keywords}")
        return translated_keywords
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
        return keywords

def find_job_pages(url):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        
        page_lang = detect_page_language(response.text)
        keywords = ["job", "career", "careers", "jobs", "hiring", "employment", "join us", "work with us", "vacancies", "karriere"]
        
        job_links = set()
        base_links = set()  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫
        
        for link in soup.find_all("a", href=True):
            href = link["href"].lower()
            if any(keyword in href for keyword in keywords):
                full_url = urljoin(url, link["href"])
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Å—ã–ª–∫–∞ –±–∞–∑–æ–≤–æ–π –∏–ª–∏ –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–æ–º
                is_subpath = False
                for base_link in base_links:
                    if full_url.startswith(base_link + "/"):
                        is_subpath = True
                        break
                
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥, –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫
                if not is_subpath:
                    job_links.add(full_url)
                    # –ï—Å–ª–∏ —ç—Ç–æ –±–∞–∑–æ–≤–∞—è —Å—Å—ã–ª–∫–∞, –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë –≤ base_links
                    if not any(c in full_url for c in ["/", "?", "#"]):  # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–∞–∑–æ–≤—É—é —Å—Å—ã–ª–∫—É
                        base_links.add(full_url)
        
        if not job_links and page_lang != "en":
            logging.info(f"üåç –ü–µ—Ä–µ–≤–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ {page_lang} –∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ–∏—Å–∫ –¥–ª—è {url}.")
            translated_keywords = translate_keywords(keywords, page_lang)
            for link in soup.find_all("a", href=True):
                href = link["href"].lower()
                if any(keyword in href for keyword in translated_keywords):
                    full_url = urljoin(url, link["href"])
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Å—ã–ª–∫–∞ –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–æ–º
                    is_subpath = False
                    for base_link in base_links:
                        if full_url.startswith(base_link + "/"):
                            is_subpath = True
                            break
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥, –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫
                    if not is_subpath:
                        job_links.add(full_url)
                        # –ï—Å–ª–∏ —ç—Ç–æ –±–∞–∑–æ–≤–∞—è —Å—Å—ã–ª–∫–∞, –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë –≤ base_links
                        if not any(c in full_url for c in ["/", "?", "#"]):
                            base_links.add(full_url)
        
        if job_links:
            logging.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(job_links)} —Å—Ç—Ä–∞–Ω–∏—Ü —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ –Ω–∞ {url}.")
        else:
            logging.warning(f"‚ö†Ô∏è –ù–∞ {url} —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        
        return list(job_links) if job_links else None
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ {url}: {e}")
        return None

def write_job_urls_to_sheet(sheet_name, websites, job_urls):
    try:
        client = authenticate_google_sheets()
        sheet = client.open(sheet_name).sheet1
        headers = sheet.row_values(1)
        
        if "Job Url" not in headers:
            sheet.update_cell(1, 2, "Job Url")
        
        for i, urls in enumerate(job_urls, start=2):
            if urls:
                sheet.update_cell(i, 2, ", ".join(urls))
            else:
                sheet.update_cell(i, 2, "–Ω–µ—Ç URL")
        
        logging.info("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ Google Sheets.")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü—É: {e}")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Selenium –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
def setup_selenium_driver():
    options = Options()
    options.headless = True  # –ó–∞–ø—É—Å–∫ –±–µ–∑ UI
    service = Service('C:\chromedriver\chromedriver.exe')
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def check_for_jobs_in_url(url, driver):
    try:
        driver.get(url)
        time.sleep(5)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        page_html = driver.page_source

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        job_keywords = [
            "Software Developer", "Data Engineer", "Software Architect", "Designer", 
            "Data Scientist", "IT Manager", "DevOps", "Tester", "Back End", 
            "Backend", "Back-End", "Front End", "Frontend", "Front-End", 
            "Data", "iOS", "Android", "Developer", "Project", "Product"
        ]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        for keyword in job_keywords:
            if keyword.lower() in page_html.lower():
                logging.info(f"üîç –í–∞–∫–∞–Ω—Å–∏–∏ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ {url} –¥–ª—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞ '{keyword}'.")
                return True
        logging.info(f"‚ö†Ô∏è –í–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ {url}.")
        return False
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ {url}: {e}")
        return False

def check_job_urls_for_keywords(sheet_name):
    try:
        client = authenticate_google_sheets()
        sheet = client.open(sheet_name).sheet1
        job_urls = sheet.col_values(2)[1:]  # –ß—Ç–µ–Ω–∏–µ URL –∏–∑ –≤—Ç–æ—Ä–æ–π –∫–æ–ª–æ–Ω–∫–∏

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Selenium
        driver = setup_selenium_driver()

        # –ü—Ä–æ—Ö–æ–¥ –ø–æ –≤—Å–µ–º —Å—Å—ã–ª–∫–∞–º
        for url in job_urls:
            has_job = check_for_jobs_in_url(url, driver)
            # –ó–∞–ø–∏—Å–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –∏–ª–∏ —Å—Ç—Ä–æ–∫—É)
            row_index = job_urls.index(url) + 2  # –ò–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏
            sheet.update_cell(row_index, 3, "–ù–∞–π–¥–µ–Ω—ã –≤–∞–∫–∞–Ω—Å–∏–∏" if has_job else "–ù–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–π")

        driver.quit()
        logging.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Å—ã–ª–æ–∫: {e}")

def main():
    sheet_name = "Parser"
    logging.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
    websites = get_business_websites(sheet_name)
    
    if not websites:
        logging.warning("‚ö†Ô∏è –ù–µ—Ç —Å–∞–π—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞.")
        return
    
    logging.info("üîé –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ —Å—Ç—Ä–∞–Ω–∏—Ü —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏...")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    with ThreadPoolExecutor(max_workers=5) as executor:
        job_urls = list(executor.map(find_job_pages, websites))
    
    logging.info("‚úçÔ∏è –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü—É...")
    write_job_urls_to_sheet(sheet_name, websites, job_urls)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π
    logging.info("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ URL –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π...")
    check_job_urls_for_keywords(sheet_name)
    
    logging.info("üéØ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    main()
